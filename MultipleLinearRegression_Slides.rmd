---
title: "Multiple Linear Regression"
author: "Jeff Canar"
date: "January 3, 2017"
output:
  ioslides_presentation:
    widescreen: true
    smaller: yes

---

```{r "setup", include = FALSE, echo = FALSE, warning = FALSE}
require(knitr)
opts_knit$set(root.dir = "~/NU/NU2016_2017/Week13")
```

## {.smaller}

Required packages for Multiple Linear Regression

1. lmSupport - To test for significant differences between models
2. MASS - for stepwise regression procedures  
3. leaps - all subsets regression
4. car - all subsets regression plot and testing assumptions

https://cran.r-project.org/web/packages/lmSupport/lmSupport.pdf  
https://cran.r-project.org/web/packages/MASS/MASS.pdf  
https://cran.r-project.org/web/packages/leaps/leaps.pdf  
https://cran.r-project.org/web/packages/car/car.pdf  

Note that this presentation attempts to recreate most everything contained within the Field's texts Dicoversing Statistics Using R (1st ed.) and Discovering Statistics using SPSS (4th ed.)

## {.smaller}

```{r}
library(Hmisc)

MyData1 <- read.table("AlbumSales2.dat",
                      header=TRUE,
                      sep="\t")

options(scipen = 999)
opar <- par()
```

## {.smaller}

```{r, echo = FALSE, warning = FALSE, message = FALSE}
hist(MyData1$sales, xlab = "Sales", main = "")
```

## {.smaller}

```{r, echo = FALSE, warning = FALSE, message = FALSE}
hist(MyData1$adverts, xlab = "Advertising", main = "")
```

## {.smaller}

```{r, echo = FALSE, warning = FALSE, message = FALSE}
hist(MyData1$attract, xlab = "Attractiveness", main = "")
```

## {.smaller}

```{r, echo = FALSE, warning = FALSE, message = FALSE}
hist(MyData1$airplay, xlab = "Airplay", main = "")
```

## {.smaller}

Check to make sure none of our predictor variables are highly correlated with one another (e.g. > .8 or thereabouts)

```{r, echo = FALSE, warning = FALSE, message = FALSE}
Correlation.Table <- cor(MyData1)
Correlation.Table
```

## {.smaller}

```{r, echo = FALSE, warning = FALSE, message = FALSE}
plot(MyData1$adverts, MyData1$sales, xlab = "Advertising Budget", ylab = "Sales")
abline(lm(MyData1$sales ~ MyData1$advert))
```

## {.smaller}

```{r, echo = FALSE, warning = FALSE, message = FALSE}
plot(MyData1$airplay, MyData1$sales, xlab = "Airplay", ylab = "Sales")
```

## {.smaller}

```{r, echo = FALSE, warning = FALSE, message = FALSE}
plot(MyData1$attract, MyData1$sales, xlab = "Attract", ylab = "Sales")
```

## {.smaller}

Sales as Predicted by Advertising Alone (Page 319)

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(lmSupport)
Album2 <- lm(sales ~ adverts, data = MyData1)
summary(Album2)
```

## {.smaller}

Sales as Predicted by Advertising, Airplay and Attractiveness (page 339)

```{r, echo = FALSE, warning = FALSE, message = FALSE}
Album3 <- lm(sales ~ adverts + airplay + attract, data = MyData1)
summary(Album3)
```

## {.smaller}

Change in \(R^2\) and significance of model improvement (Page 335)

```{r, echo = FALSE, warning = FALSE, message = FALSE}
modelCompare(Album2, Album3)
```

The change in \(R^2\) = [the second model \(R^2\)] - [the first model \(R^2\)]

.3301 = 0.6647 - 0.3346

## {.smaller}

Check the standardized regression coefficients to determine relative importance of individual variables

```{r}
library(lm.beta)
lm.beta(Album3)

```

## {.smaller}

Here are the same results, using the built in "anova" function, but the actual change in \(R^2\) is not provided.  Therefore, you might prefer to use the "modelCompare" function from the "lmSupport" package.  The results and conclusions are the same, but the "modelCompare" function does the change in \(R^2\) calculation for you, rather than doing it by hand.

```{r}
anova(Album2, Album3)
```

## {.smaller}

Backward Stepwise ("MASS" Package)

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(MASS)

backward.step <- stepAIC(Album3,
                         direction = "backward",
                         trace = TRUE,
                         test = "F")
backward.step$anova

```

## {.smaller}

Forward Stepwise ("MASS" Package)

```{r, echo = FALSE, warning = FALSE, message = FALSE}
forward.step <- stepAIC(Album3,
                        direction = "forward",
                        trace = TRUE,
                        test = "F")
forward.step$anova
```

## {.smaller}

Stepwise? ("MASS" Package)

```{r, echo = FALSE, warning = FALSE, message = FALSE}
both.step <- stepAIC(Album3, direction = "both")
both.step$anova
```

## {.smaller}

Set up an all subsets regression ("leaps" package) ....

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(leaps)
Album4 <- regsubsets(sales ~ adverts + airplay + attract, data = MyData1, nbest = 10)
summary(Album4)
```

## {.smaller}

Plot the \(R^2\) associated with every possible model.  Read the graph (a) horizontally, (b) row by row, (c) from the bottom to the top, to determine which variables are being included.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
plot(Album4, scale = "r2")
```

## {.smaller}

A similar plot based on subset size ("car" package)

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(car)
subsets(Album4, statistic = "rsq", legend = c(2.5, .3))
```

## {.smaller}

Check that the error variance is constant for our advertisting predictor alone ("car" package).  This does provide a statistical test (Breusch-Pagan) which will tell you if the error variance changes across a linear combination of predictors.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
ncvTest(Album2)
spreadLevelPlot(Album2, main = "Simple Linear Model")
```

## {.smaller}

Check that the error variance is constant when using all our predictors  
("car" package)

```{r, echo = FALSE, warning = FALSE, message = FALSE}
ncvTest(Album3)
spreadLevelPlot(Album3, main = "Multiple Linear Model")
```

## {.smaller}

Check for normally distributed errors when using advertising dollars  
("MASS" package)

```{r, echo = FALSE, warning = FALSE, message = FALSE}
#### Normally distributed residuals
sresid1 <- studres(Album2)
hist(sresid1, main = "Simple Linear Regression \nStandardized Residuals", freq = FALSE)
curve(dnorm(x, mean=mean(sresid1), sd=sd(sresid1)), add = TRUE)
```

## {.smaller}

Check for normally distributed errors when using all predictors  
("MASS" package)

```{r, echo = FALSE, warning = FALSE, message = FALSE}
sresid2 <- studres(Album3)
hist(sresid2, main = "Multiple Linear Regression \nStandardized Residuals", freq = FALSE)
curve(dnorm(x, mean=mean(sresid2), sd=sd(sresid2)), add = TRUE)
```

## {.smaller}

Normally distributed errors using a qqplot with advertising budget.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
qqPlot(Album2, main = "Simple Linear Regression")
```

## {.smaller}

Normally distributed errors using a qqplot with all predictors.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
qqPlot(Album3, main = "Multiple Linear Regression")
```

## {.smaller}

Check for correlated errors ("car" package).  The first set of results is when we just look at advertising dollars.  The second set of results is when we look at all three predictors.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
#### Independent errors - Durbin Watson
dw1 <- durbinWatsonTest(Album2)
dw2 <- durbinWatsonTest(Album3)
dw1
dw2
```

## {.smaller}

Check for Outliers and Influential Cases (Page 288-291)

```{r, echo = TRUE, warning = FALSE, message = FALSE}
# Create new variables in our data frame to store all case-by-case
# diagnostic values

MyData1$Predicted.Values <- predict(Album3)
MyData1$Residuals <- resid(Album3)
MyData1$Standardized.Residuals <- rstandard(Album3)
MyData1$Studentized.Residuals <- rstudent(Album3)
MyData1$Cooks.Distance <- cooks.distance(Album3)
MyData1$dfbeta <- dfbeta(Album3)
MyData1$dffit <- dffits(Album3)
MyData1$Leverage <- hatvalues(Album3)
MyData1$Covariance.Ratios <- covratio(Album3)
```

## {.smaller}

Shapiro-Wilks test for normality of errors (residuals) - All Predictors

```{r}
shapiro.test(MyData1$Residuals)
```

## {.smaller}

Predicted vs Residuals diagnostic plots

```{r, echo = FALSE, warning = FALSE, message = FALSE}
plot(MyData1$Predicted.Values, MyData1$Residuals,
     xlab = "Fitted Values \nlm(sales ~ adverts + airplay + attract)",
     ylab = "Residuals",
     main = "Residual vs Fitted")
abline(h = 0, col = "red", lty = 2)
```

## {.smaller}

Check for number of cases with standardized residuals <> +/- 2

```{r, echo = FALSE, warning = FALSE, message = FALSE}
MyData1$Large.residuals <- MyData1$Standardized.Residuals < -2 | MyData1$Standardized.Residuals > 2
sum(MyData1$Large.residuals)
Outliers <- MyData1[which(MyData1$Large.residuals == TRUE), c(2, 5, 7)]
Outliers
```

## {.smaller}

Check remaining diagnostics on outlying cases - Note that Field's only looks  
at cases which were identified as having std. residuals <> +/- 2.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
Outliers.2 <- MyData1[which(MyData1$Large.residuals == TRUE), c(7, 9, 12, 13)]
Outliers.2
```

## {.smaller}

Check remaining diagnostics on outlying cases (using all cases) -cont-

```{r, echo = TRUE, warning = FALSE, message = FALSE}
MyData1$Cooks.Outliers <- MyData1$Cooks.Distance > 1
# Number of Cooks Outliers > 1
sum(MyData1$Cooks.Outliers)
MyData1[which(MyData1$Cooks.Outliers == TRUE), c(2, 14)]
```

## {.smaller}

```{r, echo = FALSE, warning = FALSE, message = FALSE}
# Number of cases with Leverage > 2 * (k + 1)/n
k <- 3
n <- 200
MyData1$Leverage.Outliers <- MyData1$Leverage > (2 * ((k+1)/n))
sum(MyData1$Leverage.Outliers)
MyData1[which(MyData1$Leverage.Outliers == TRUE), c(2, 12, 16)]
```

## {.smaller}

```{r, echo = FALSE, warning = FALSE, message = FALSE}
# Number of cases with covariance ratio outside limits
k <- 3
n <- 200
MyData1$CVR.Outliers <- MyData1$Covariance.Ratios > 1 + (3*(k+1))/n |
                        MyData1$Covariance.Ratios < 1 - (3*(k+1))/n
sum(MyData1$CVR.Outliers)
MyData1[which(MyData1$CVR.Outliers == TRUE), c(2, 13, 17)]
```


## {.smaller}

Assess the assumption of independent errors 

```{r, echo = TRUE, warning = FALSE, message = FALSE}
durbinWatsonTest(Album3)
```

## {.smaller}

Assess multicollinearity using Variance Inflation Factor (VIF)

```{r, echo = TRUE, warning = FALSE, message = FALSE}
k <- 3
vif(Album3) # VIF By Variable
mean(vif(Album3)) # Average VIF

1/vif(Album3) # Tolerance By Variable
```

## {.smaller}

In summary:

1. Check your basic, univariate descriptive statistics to make sure things look o.k. (e.g. somewhat normally distributed predictors, no outliers, etc...).

2. Check bi-variate relationships between all predictors and the outcome.  Look for excessively high correlations between predictors (e.g. correlations between predictors >= .8), and consider dropping a variable if it shows a high correlation with another.  If they are that highly correlated, there is no reason to include each variable.  Just pick one.

3. Check bi-variate scatterplots, looking for deviations from "linear" relationships between each predictor and outcome.

4. Build your regression model(s), however you see fit.  It can be forced entry (include everything), hierarchical (add variables based on hypothesis), or exploratory (the various stepwise procedures).

5. Compare each consecutive model with the previous (as necessary and appropriate), and draw your conclusions.

6. Check the various assumptions of regression and adjust accordingly.
